{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Evaluation Code\n",
    "\n",
    "This notebook will be very __similar__ to the code I use to evaluate your results - it is provided for __your convenience__ so that you can use it to evaluate your preprocessing results at any time before your __final submission__.\n",
    "\n",
    "Please note that the results here will __NOT__ be the same as my evaluation results.\n",
    "\n",
    "Let's start with loading the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import required package for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import required packages for splitting data\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import required packages for evaluating models\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# import `logistic regression` model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you should load __your__ data. In this case, I am using a sample dataset (`GroupX.csv`) which contains 6 predictors (`X1 - X6`) and two target variables (`Y1, Y2`).\n",
    "\n",
    "Please make sure you change the data to your __OWN__ dataset when using this code.\n",
    "\n",
    "__NOTE__:\n",
    "1. Your dataset maybe very different from the sample dataset.\n",
    "2. Please follow this structure when submitting your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>63.008</td>\n",
       "      <td>60.735</td>\n",
       "      <td>52.482</td>\n",
       "      <td>45.474</td>\n",
       "      <td>48.495</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38.417</td>\n",
       "      <td>52.756</td>\n",
       "      <td>66.680</td>\n",
       "      <td>45.059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>58.163</td>\n",
       "      <td>61.107</td>\n",
       "      <td>30.678</td>\n",
       "      <td>49.188</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>57.762</td>\n",
       "      <td>67.167</td>\n",
       "      <td>37.176</td>\n",
       "      <td>64.204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>25.930</td>\n",
       "      <td>44.696</td>\n",
       "      <td>58.801</td>\n",
       "      <td>48.079</td>\n",
       "      <td>21.823</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1      X2      X3      X4      X5      X6  Y1  Y2\n",
       "0   1  63.008  60.735  52.482  45.474  48.495   0   1\n",
       "1   0  38.417  52.756  66.680  45.059   0.000   1   0\n",
       "2   0  58.163  61.107  30.678  49.188   0.000   1   0\n",
       "3   0  57.762  67.167  37.176  64.204   0.000   1   1\n",
       "4   1  25.930  44.696  58.801  48.079  21.823   0   1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('GroupX.csv', header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'test1.csv' does not exist: b'test1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1d65dcb872ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m data = pd.read_csv('test1.csv',usecols =[ 'C1' , 'C2' , 'C3_p' ,'C4' , 'C5_p' , 'C6_p' , \n\u001b[0;32m----> 2\u001b[0;31m                                         'C7' , 'T1' ,'T2' ,'T3','T4' , 'T5', 'S1','S2','S3' ,'div_manufacturing' ,'div_other' ,'div_services' ,'Y1', 'Y2' ])\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'test1.csv' does not exist: b'test1.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('test1.csv',usecols =[ 'C1' , 'C2' , 'C3_p' ,'C4' , 'C5_p' , 'C6_p' , \n",
    "                                        'C7' , 'T1' ,'T2' ,'T3','T4' , 'T5', 'S1','S2','S3' ,'div_manufacturing' ,'div_other' ,'div_services' ,'Y1', 'Y2' ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_imputed_outliers_fixed_min_max_cube_root.csv',usecols = ['C3_Imput_p', 'Y1','Y2', \n",
    "                                                               'C1_Imput_outliner_fix_min_max',\n",
    "                                                                'C2_Imput_min_max',\n",
    "                                                                'C4_Imput_min_max',\n",
    "                                                                'C5_Imput_p_outliner_fix_min_max',\n",
    "                                                                'C6_Imput_p_outliner_fix_min_max_cube_root',\n",
    "                                                                'C7_Imput_outliner_fix_min_max_cube_root',\n",
    "                                                                'div_manufacturing','div_other','div_services',\n",
    "                                                                'T3_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'T4_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'T5_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'S1_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'S2_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'S3_Imput_ratio_outliner_fix_min_max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking your data types and make sure it follows the data dictionary would be an important step, you can do that using the `.dtypes` attribute.\n",
    "\n",
    "__NOTE__: all __continuous__ faetures will be in `float64` data type, and all __categorical__ features will be in `int64` data type (given you already coded (per __suggest task \\#6__ in the competition document) them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "div_manufacturing                              int64\n",
       "div_other                                      int64\n",
       "div_services                                   int64\n",
       "Y1                                             int64\n",
       "Y2                                             int64\n",
       "C3_Imput_p                                     int64\n",
       "C1_Imput_outliner_fix_min_max                float64\n",
       "C2_Imput_min_max                             float64\n",
       "C4_Imput_min_max                             float64\n",
       "C5_Imput_p_outliner_fix_min_max              float64\n",
       "T3_Imput_ratio_outliner_fix_min_max          float64\n",
       "T4_Imput_ratio_outliner_fix_min_max          float64\n",
       "T5_Imput_ratio_outliner_fix_min_max          float64\n",
       "S1_Imput_ratio_outliner_fix_min_max          float64\n",
       "S2_Imput_ratio_outliner_fix_min_max          float64\n",
       "S3_Imput_ratio_outliner_fix_min_max          float64\n",
       "C6_Imput_p_outliner_fix_min_max_cube_root    float64\n",
       "C7_Imput_outliner_fix_min_max_cube_root      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "677    1\n",
       "678    1\n",
       "679    0\n",
       "680    0\n",
       "681    0\n",
       "Name: Y2, Length: 682, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to specify your targets and predictors. __NOTE__ we have two targets here (`Y1, Y2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = data.Y1\n",
    "y2 = data.Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(682, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very possible that you will use different sets of the predictors for `Y1` and `Y2`. Now let's define them.\n",
    "\n",
    "First, let's define predictors for `Y1` - which will be the first 5 features in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C6_Imput_p_outliner_fix_min_max_cube_root',\n",
       " 'C3_Imput_p',\n",
       " 'C1_Imput_outliner_fix_min_max',\n",
       " 'C2_Imput_min_max',\n",
       " 'C4_Imput_min_max',\n",
       " 'C5_Imput_p_outliner_fix_min_max']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cols =  [ 'Y1','Y2','C6_Imput_p_outliner_fix_min_max_cube_root', 'C3_Imput_p',\n",
    "        'C1_Imput_outliner_fix_min_max',\n",
    "                                                                'C2_Imput_min_max',\n",
    "                                                                'C4_Imput_min_max',\n",
    "                                                                'C5_Imput_p_outliner_fix_min_max',\n",
    "                                                                \n",
    "                                                                'C7_Imput_outliner_fix_min_max_cube_root',\n",
    "                                                                'div_manufacturing','div_other','div_services',\n",
    "                                                                'T3_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'T4_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'T5_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'S1_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'S2_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'S3_Imput_ratio_outliner_fix_min_max' ]\n",
    "# first 5 features \n",
    "cols[2:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cols =  [ 'Y1','Y2','C6_Imput_p_outliner_fix_min_max_sqrt', 'C3_Imput_p',\\n        \\n                                                                'C1_Imput_outliner_fix_min_max',\\n                                                                'C2_Imput_min_max',\\n                                                                'C4_Imput_min_max_sqrt',\\n                                                                'C5_Imput_p_outliner_fix_min_max_sqrt',\\n                                                                \\n                                                                'C7_Imput_outliner_fix_min_max_sqrt',\\n                                                                'div_manufacturing','div_other','div_services',\\n                                                                'T3_Imput_ratio_outliner_fix_min_max_sqrt',\\n                                                                'T4_Imput_ratio_outliner_fix_min_max',\\n                                                                'T5_Imput_ratio_outliner_fix_min_max',\\n                                                                'S1_Imput_ratio_outliner_fix_min_max_sqrt',\\n                                                                'S2_Imput_ratio_outliner_fix_min_max_sqrt',\\n                                                                'S3_Imput_ratio_outliner_fix_min_max']\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''cols =  [ 'Y1','Y2','C6_Imput_p_outliner_fix_min_max_sqrt', 'C3_Imput_p',\n",
    "        \n",
    "                                                                'C1_Imput_outliner_fix_min_max',\n",
    "                                                                'C2_Imput_min_max',\n",
    "                                                                'C4_Imput_min_max_sqrt',\n",
    "                                                                'C5_Imput_p_outliner_fix_min_max_sqrt',\n",
    "                                                                \n",
    "                                                                'C7_Imput_outliner_fix_min_max_sqrt',\n",
    "                                                                'div_manufacturing','div_other','div_services',\n",
    "                                                                'T3_Imput_ratio_outliner_fix_min_max_sqrt',\n",
    "                                                                'T4_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'T5_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'S1_Imput_ratio_outliner_fix_min_max_sqrt',\n",
    "                                                                'S2_Imput_ratio_outliner_fix_min_max_sqrt',\n",
    "                                                                'S3_Imput_ratio_outliner_fix_min_max']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_y1 =  [ 'Y1','Y2','C6_Imput_p_outliner_fix_min_max_cube_root', \n",
    "      \n",
    "        'C1_Imput_outliner_fix_min_max',\n",
    "                                                               'C2_Imput_min_max',\n",
    "                                                                'C4_Imput_min_max',\n",
    "                                                                'C5_Imput_p_outliner_fix_min_max',\n",
    "\n",
    "                                                                'T3_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'T4_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                \n",
    "                                                                'S2_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 5\n",
      "Selected Features: [ True  True False  True  True  True]\n",
      "Feature Ranking: [1 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below code to select the first 5 features as predictors for `Y1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1_Imput_outliner_fix_min_max</th>\n",
       "      <th>C2_Imput_min_max</th>\n",
       "      <th>C4_Imput_min_max</th>\n",
       "      <th>C5_Imput_p_outliner_fix_min_max</th>\n",
       "      <th>T3_Imput_ratio_outliner_fix_min_max</th>\n",
       "      <th>T4_Imput_ratio_outliner_fix_min_max</th>\n",
       "      <th>S2_Imput_ratio_outliner_fix_min_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.462810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.749962</td>\n",
       "      <td>0.476417</td>\n",
       "      <td>0.638012</td>\n",
       "      <td>0.534453</td>\n",
       "      <td>0.517533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.589876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583748</td>\n",
       "      <td>0.609551</td>\n",
       "      <td>0.537617</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.657533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.330579</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717213</td>\n",
       "      <td>0.410536</td>\n",
       "      <td>0.642696</td>\n",
       "      <td>0.524832</td>\n",
       "      <td>0.302522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.822314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714502</td>\n",
       "      <td>0.401299</td>\n",
       "      <td>0.718941</td>\n",
       "      <td>0.265799</td>\n",
       "      <td>0.366592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.289256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499347</td>\n",
       "      <td>0.458048</td>\n",
       "      <td>0.436206</td>\n",
       "      <td>0.393150</td>\n",
       "      <td>0.579842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C1_Imput_outliner_fix_min_max  C2_Imput_min_max  C4_Imput_min_max  \\\n",
       "0                       0.462810               1.0          0.749962   \n",
       "1                       0.589876               0.0          0.583748   \n",
       "2                       0.330579               1.0          0.717213   \n",
       "3                       0.822314               1.0          0.714502   \n",
       "4                       0.289256               1.0          0.499347   \n",
       "\n",
       "   C5_Imput_p_outliner_fix_min_max  T3_Imput_ratio_outliner_fix_min_max  \\\n",
       "0                         0.476417                             0.638012   \n",
       "1                         0.609551                             0.537617   \n",
       "2                         0.410536                             0.642696   \n",
       "3                         0.401299                             0.718941   \n",
       "4                         0.458048                             0.436206   \n",
       "\n",
       "   T4_Imput_ratio_outliner_fix_min_max  S2_Imput_ratio_outliner_fix_min_max  \n",
       "0                             0.534453                             0.517533  \n",
       "1                             0.545989                             0.657533  \n",
       "2                             0.524832                             0.302522  \n",
       "3                             0.265799                             0.366592  \n",
       "4                             0.393150                             0.579842  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_y1 = data[cols_y1[3:]]\n",
    "predictors_y1.head()\n",
    "#predictors_y1.pop('Y1')\n",
    "#predictors_y1.pop('Y2')\n",
    "predictors_y1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 5\n",
      "Selected Features: [ True  True False  True  True  True]\n",
      "Feature Ranking: [1 1 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 5)\n",
    "fit = rfe.fit(predictors_y1, y1)\n",
    "print(\"Num Features: %s\" % (fit.n_features_))\n",
    "print(\"Selected Features: %s\" % (fit.support_))\n",
    "print(\"Feature Ranking: %s\" % (fit.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_y2 =  [ 'Y1','Y2','C6_Imput_p_outliner_fix_min_max_cube_root', \n",
    "          \n",
    "       \n",
    "                                                              'C2_Imput_min_max',\n",
    "                                                                'C4_Imput_min_max',\n",
    "                                                                \n",
    "           'div_manufacturing','div_other','div_services',\n",
    "                                               \n",
    "                                                                'S1_Imput_ratio_outliner_fix_min_max',\n",
    "                                                                'S2_Imput_ratio_outliner_fix_min_max',\n",
    "                                                               'S3_Imput_ratio_outliner_fix_min_max' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon investigation of the data, we know we have __six__ features (`X1 - X6`) predicting `Y2`. Use similar code (as below) to select them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C6_Imput_p_outliner_fix_min_max_cube_root</th>\n",
       "      <th>C2_Imput_min_max</th>\n",
       "      <th>C4_Imput_min_max</th>\n",
       "      <th>div_manufacturing</th>\n",
       "      <th>div_other</th>\n",
       "      <th>div_services</th>\n",
       "      <th>S1_Imput_ratio_outliner_fix_min_max</th>\n",
       "      <th>S2_Imput_ratio_outliner_fix_min_max</th>\n",
       "      <th>S3_Imput_ratio_outliner_fix_min_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.857094</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.749962</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437894</td>\n",
       "      <td>0.517533</td>\n",
       "      <td>0.462564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583748</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.234817</td>\n",
       "      <td>0.657533</td>\n",
       "      <td>0.458341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.717213</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611693</td>\n",
       "      <td>0.302522</td>\n",
       "      <td>0.500343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714502</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611693</td>\n",
       "      <td>0.366592</td>\n",
       "      <td>0.653084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.656799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499347</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.393079</td>\n",
       "      <td>0.579842</td>\n",
       "      <td>0.489061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C6_Imput_p_outliner_fix_min_max_cube_root  C2_Imput_min_max  \\\n",
       "0                                   0.857094               1.0   \n",
       "1                                   0.000000               0.0   \n",
       "2                                   0.000000               1.0   \n",
       "3                                   0.000000               1.0   \n",
       "4                                   0.656799               1.0   \n",
       "\n",
       "   C4_Imput_min_max  div_manufacturing  div_other  div_services  \\\n",
       "0          0.749962                  1          0             0   \n",
       "1          0.583748                  1          0             0   \n",
       "2          0.717213                  1          0             0   \n",
       "3          0.714502                  1          0             0   \n",
       "4          0.499347                  0          1             0   \n",
       "\n",
       "   S1_Imput_ratio_outliner_fix_min_max  S2_Imput_ratio_outliner_fix_min_max  \\\n",
       "0                             0.437894                             0.517533   \n",
       "1                             0.234817                             0.657533   \n",
       "2                             0.611693                             0.302522   \n",
       "3                             0.611693                             0.366592   \n",
       "4                             0.393079                             0.579842   \n",
       "\n",
       "   S3_Imput_ratio_outliner_fix_min_max  \n",
       "0                             0.462564  \n",
       "1                             0.458341  \n",
       "2                             0.500343  \n",
       "3                             0.653084  \n",
       "4                             0.489061  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_y2 = data[cols_y2[2:]]\n",
    "#predictors_y2.pop('Y1')\n",
    "#predictors_y2.pop('Y2')\n",
    "predictors_y2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 5\n",
      "Selected Features: [ True False  True False  True False  True  True False]\n",
      "Feature Ranking: [1 3 1 5 1 4 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 5)\n",
    "fit = rfe.fit(predictors_y2, y2)\n",
    "print(\"Num Features: %s\" % (fit.n_features_))\n",
    "print(\"Selected Features: %s\" % (fit.support_))\n",
    "print(\"Feature Ranking: %s\" % (fit.ranking_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the key part of this notebook - which generates a `logistic regression` model to predict `Y1`/`Y2`.\n",
    "\n",
    "The code works this way:\n",
    "\n",
    "1. We generate two lists `f1_score_lst` and `auc_lst` to store f1_score and AUC from each of the `10` runs of the model;\n",
    "2. Define model:\n",
    "    1. We define a `LogisticRegression()` model;\n",
    "    \n",
    "    2. We split predictors (`predictors_y1`) and target `y1` to training (80%) and testing (20%);\n",
    "    \n",
    "    3. We fit the model `clf` to the training data, then use it to predict on the testing data;\n",
    "    \n",
    "    4. We also defined a `10-fold cross validation` to make sure our model do not overfit - see [here](https://scikit-learn.org/stable/modules/cross_validation.html) for more info;\n",
    "    \n",
    "    5. We append the f1_score and AUC of current model to the lists (`f1_score_lst` and `auc_lst`) we defined earlier.\n",
    "  \n",
    "3. Print out average f1_score and AUC for all 10 runs;\n",
    "4. Print out average average accuracy from cross validation\n",
    "5. Print out confusion matrix and classification report for the __last__ model.\n",
    "\n",
    "__NOTE__: Step 3 provides the evaluation results we need; step 4 - 5 can be used to verify the results from step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.6111; AUC 0.6095 \n",
      "Accuracy of classifier on test set: 0.61\n",
      "10-fold cross validation average accuracy of classifier: 0.589\n",
      "Confusion Matrix for Logistic Regression Classfier:\n",
      "[[35 30]\n",
      " [23 49]]\n",
      "Classification Report for Logistic Regression Classfier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.54      0.57        65\n",
      "           1       0.62      0.68      0.65        72\n",
      "\n",
      "    accuracy                           0.61       137\n",
      "   macro avg       0.61      0.61      0.61       137\n",
      "weighted avg       0.61      0.61      0.61       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,100):\n",
    "    #Model building\n",
    "    clf = LogisticRegression()\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(predictors_y1, y1, test_size=0.2, random_state=123)\n",
    "    clf.fit(X1_train, y1_train)\n",
    "\n",
    "    y1_pred = clf.predict(X1_test)\n",
    "\n",
    "    \n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=123, shuffle=True)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf, X1_train, y1_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    #calculate f1-score and AUC\n",
    "    \n",
    "    clf_roc_auc = roc_auc_score(y1_test, y1_pred)\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y1_test, y1_pred, average='weighted')[2])\n",
    "    auc_lst.append(clf_roc_auc)\n",
    "\n",
    "\n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "#result=logit_model.fit()\n",
    "confusion_matrix_y1 = confusion_matrix(y1_test, y1_pred)\n",
    "\n",
    "\n",
    "#print(result.summary())\n",
    "print('Accuracy of classifier on test set: {:.2f}'.format(clf.score(X1_test, y1_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of classifier: %.3f\" % (results.mean()))\n",
    "\n",
    "print('Confusion Matrix for Logistic Regression Classfier:')\n",
    "print(confusion_matrix_y1)\n",
    "\n",
    "print('Classification Report for Logistic Regression Classfier:')\n",
    "print(classification_report(y1_test, y1_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code are used to evaluate model toward `Y2`. It is very similar to the code above - key difference is that `Y2` is imbalanced - so I wrote some code (under `# Begin oversampling`) to deal with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.6105; AUC 0.6188 \n",
      "Accuracy of classifier on test set: 0.577\n",
      "10-fold cross validation average accuracy of clf1: 0.629\n",
      "Confusion Matrix for Classfier:\n",
      "[[28 14]\n",
      " [44 51]]\n",
      "Classification Report for Classfier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.67      0.49        42\n",
      "           1       0.78      0.54      0.64        95\n",
      "\n",
      "    accuracy                           0.58       137\n",
      "   macro avg       0.59      0.60      0.56       137\n",
      "weighted avg       0.66      0.58      0.59       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,100):\n",
    "    #Model building\n",
    "    clf1 = LogisticRegression()\n",
    "\n",
    "    \n",
    "    # Splitting data into testing and training\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(predictors_y2, y2, test_size=0.2, random_state=123)\n",
    "    \n",
    "    # Begin oversampling\n",
    "    oversample = pd.concat([X2_train,y2_train],axis=1)\n",
    "    max_size = oversample['Y2'].value_counts().max()\n",
    "    lst = [oversample]\n",
    "    for class_index, group in oversample.groupby('Y2'):\n",
    "        lst.append(group.sample(max_size-len(group), replace=True))\n",
    "    X2_train = pd.concat(lst)\n",
    "    y2_train=pd.DataFrame.copy(X2_train['Y2'])\n",
    "    del X2_train['Y2']\n",
    "    \n",
    "    # fitting model on oversampled data\n",
    "    clf1.fit(X2_train, y2_train)\n",
    "    \n",
    "    y2_pred = clf1.predict(X2_test)\n",
    "    \n",
    "    \n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=123, shuffle=True)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf1, X2_train, y2_train, cv=kfold, scoring=scoring)\n",
    "    \n",
    "    #calculate f1-score and AUC\n",
    "    \n",
    "    clf1_roc_auc = roc_auc_score(y2_test, y2_pred)\n",
    "    \n",
    "    \n",
    "    #calculate average f1-score and AUC\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y2_test, y2_pred, average='weighted')[2])\n",
    "    auc_lst.append(clf1_roc_auc)\n",
    "    \n",
    "    \n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "confusion_matrix_y2 = confusion_matrix(y2_test, y2_pred)\n",
    "\n",
    "\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(clf1.score(X2_test, y2_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of clf1: %.3f\" % (results.mean()))\n",
    "\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y2)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y2_test, y2_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Y2'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
